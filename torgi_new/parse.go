package torgi_new

import (
	torgi_online "bitrix_app/torgi-online"
	"fmt"
	"github.com/PuerkitoBio/goquery"
	"log"
	"net/http"
	"regexp"
	"strconv"
	"strings"
	"time"
)

var CompCount int

// extractNumberFromText –∏–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ –∏–∑ —Å—Ç—Ä–æ–∫–∏ —Å —Ç–µ–∫—Å—Ç–æ–º
func extractNumberFromText(text string) int {
	re := regexp.MustCompile(`\d+`)
	match := re.FindString(text)
	num, err := strconv.Atoi(match)
	if err != nil {
		return 0
	}
	return num
}

// IsValidOrder –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ –∑–∞–∫—É–ø–∫–∞ –∫ "–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω"
func IsValidOrder(url string) bool {
	log.Printf("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–∫—É–ø–∫—É: %s", url)

	// –ó–∞–≥—Ä—É–∂–∞–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∑–∞–∫—É–ø–∫–∏
	htmlContent, err := GetInn(url, "")
	if err != nil {
		log.Printf("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∑–∞–∫—É–ø–∫–∏ %s: %s\n", url, err)
		return false
	}

	doc, err := goquery.NewDocumentFromReader(strings.NewReader(htmlContent))
	if err != nil {
		log.Printf("‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML –∑–∞–∫—É–ø–∫–∏ %s: %s\n", url, err)
		return false
	}

	found := false

	// –ó–∞–≥—Ä—É–∂–∞–µ–º HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—É
	oldDoc, err := torgi_online.FetchHtmlOld(url)
	if err != nil {
		log.Printf("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ HTML –¥–ª—è url %s: %v", url, err)
		return false
	}

	// –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–∞ #7
	elementOne := oldDoc.Find(".common-text__value").Eq(1) // –ò–Ω–¥–µ–∫—Å 6 –¥–ª—è —Å–µ–¥—å–º–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ (–Ω—É–º–µ—Ä–∞—Ü–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 0)
	textOne := strings.TrimSpace(elementOne.Text())
	elementTwo := oldDoc.Find(".common-text__value").Eq(2) // –ò–Ω–¥–µ–∫—Å 6 –¥–ª—è —Å–µ–¥—å–º–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ (–Ω—É–º–µ—Ä–∞—Ü–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 0)
	textTwo := strings.TrimSpace(elementTwo.Text())
	elementThree := oldDoc.Find(".common-text__value").Eq(3) // –ò–Ω–¥–µ–∫—Å 6 –¥–ª—è —Å–µ–¥—å–º–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ (–Ω—É–º–µ—Ä–∞—Ü–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 0)
	textThree := strings.TrimSpace(elementThree.Text())
	elementFour := oldDoc.Find(".common-text__value").Eq(4) // –ò–Ω–¥–µ–∫—Å 6 –¥–ª—è —Å–µ–¥—å–º–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ (–Ω—É–º–µ—Ä–∞—Ü–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 0)
	textFour := strings.TrimSpace(elementFour.Text())
	elementFive := oldDoc.Find(".common-text__value").Eq(5) // –ò–Ω–¥–µ–∫—Å 6 –¥–ª—è —Å–µ–¥—å–º–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ (–Ω—É–º–µ—Ä–∞—Ü–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 0)
	textFive := strings.TrimSpace(elementFive.Text())
	elementSix := oldDoc.Find(".common-text__value").Eq(6) // –ò–Ω–¥–µ–∫—Å 6 –¥–ª—è —Å–µ–¥—å–º–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ (–Ω—É–º–µ—Ä–∞—Ü–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 0)
	textSix := strings.TrimSpace(elementSix.Text())
	elementSeven := oldDoc.Find(".common-text__value").Eq(7) // –ò–Ω–¥–µ–∫—Å 6 –¥–ª—è —Å–µ–¥—å–º–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ (–Ω—É–º–µ—Ä–∞—Ü–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 0)
	textSeven := strings.TrimSpace(elementSeven.Text())
	elementEight := oldDoc.Find(".common-text__value").Eq(8) // –ò–Ω–¥–µ–∫—Å 6 –¥–ª—è —Å–µ–¥—å–º–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ (–Ω—É–º–µ—Ä–∞—Ü–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 0)
	textEight := strings.TrimSpace(elementEight.Text())

	//log.Printf("–ó–Ω–∞—á–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–∞ #7: %s", text)

	// –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞, –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
	if strings.Contains(textOne, "–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω") {
		log.Printf("–ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –¥–ª—è url %s: –Ω–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç '–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω'.", url)
		return false
	}
	if strings.Contains(textTwo, "–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω") {
		log.Printf("–ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –¥–ª—è url %s: –Ω–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç '–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω'.", url)
		return false
	}
	if strings.Contains(textThree, "–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω") {
		log.Printf("–ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –¥–ª—è url %s: –Ω–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç '–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω'.", url)
		return false
	}
	if strings.Contains(textFour, "–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω") {
		log.Printf("–ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –¥–ª—è url %s: –Ω–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç '–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω'.", url)
		return false
	}
	if strings.Contains(textFive, "–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω") {
		log.Printf("–ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –¥–ª—è url %s: –Ω–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç '–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω'.", url)
		return false
	}
	if strings.Contains(textSix, "–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω") {
		log.Printf("–ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –¥–ª—è url %s: –Ω–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç '–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω'.", url)
		return false
	}
	if strings.Contains(textSeven, "–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω") {
		log.Printf("–ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –¥–ª—è url %s: –Ω–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç '–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω'.", url)
		return false
	}
	if strings.Contains(textEight, "–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω") {
		log.Printf("–ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –¥–ª—è url %s: –Ω–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç '–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω'.", url)
		return false
	}
	// –ù–∞—Ö–æ–¥–∏–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ `.common-text__title` –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
	doc.Find(".common-text__title").Each(func(i int, s *goquery.Selection) {
		log.Printf("üîé –ó–∞–≥–æ–ª–æ–≤–æ–∫ #%d: %s", i+1, s.Text())
		text := strings.TrimSpace(s.Text())

		// –ï—Å–ª–∏ –Ω–∞—à–ª–∏ "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–ª–æ—â–∞–¥–∫–∏"
		if strings.Contains(text, "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–ª–æ—â–∞–¥–∫–∏") {
			// –°–ª–µ–¥—É—é—â–∏–π `.common-text__value` —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–ª–æ—â–∞–¥–∫–∏
			value := s.Parent().Find(".common-text__value").First().Text()
			value = strings.TrimSpace(value)

			log.Printf("üìù –ù–∞–π–¥–µ–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–ª–æ—â–∞–¥–∫–∏: '%s'", value) // –û—Ç–ª–∞–¥–∫–∞

			if strings.Contains(value, "–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω") {
				log.Printf("‚ö†Ô∏è –ó–∞–∫—É–ø–∫–∞ %s –∏—Å–∫–ª—é—á–µ–Ω–∞ (–≠–¢–ü –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω)\n", url)
				found = true
			}
		}
	})

	return !found
}

// ProcessCompanies - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ —Å–ø–∏—Å–∫–∞
func ProcessCompanies(arrayAllComp []map[string]interface{}, allOrdersHrefs []string, arUsers map[int]string, logTraceID string) ([]string, map[int]string) {
	todayNew := time.Now().AddDate(0, 0, -3).Format("02.01.2006")

	newCompaniesListArr := make(map[int]string)
	arrKey := 0

	processedCount := 0

	for _, oneComp := range arrayAllComp {

		COMPInn, ok := oneComp["UF_INN"].(string)
		if !ok || COMPInn == "" {
			continue
		}

		COMPIDStr, ok := oneComp["ID"].(string)
		if !ok {
			COMPIDStr = fmt.Sprintf("%.0f", oneComp["ID"].(float64))
		}
		COMPID, _ := strconv.Atoi(COMPIDStr)

		COMPUserIDStr, ok := oneComp["ASSIGNED_BY_ID"].(string)
		if !ok {
			COMPUserIDStr = fmt.Sprintf("%.0f", oneComp["ASSIGNED_BY_ID"].(float64))
		}
		COMPUserID, _ := strconv.Atoi(COMPUserIDStr)

		COMPName, _ := oneComp["TITLE"].(string)

		log.Printf("[%s] –û–±—Ä–∞–±–æ—Ç–∫–∞ –ò–ù–ù: %s (‚Ññ%d)\n", logTraceID, COMPInn, processedCount+1)

		htmlContent, err := GetInn(COMPInn, todayNew)
		if err != nil {
			log.Printf("[%s] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ HTML –¥–ª—è –ò–ù–ù %s: %s\n", logTraceID, COMPInn, err)
			continue
		}

		doc, err := goquery.NewDocumentFromReader(strings.NewReader(htmlContent))
		if err != nil {
			log.Printf("[%s] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML –¥–ª—è –ò–ù–ù %s: %s\n", logTraceID, COMPInn, err)
			continue
		}

		totalText := doc.Find(".search-results__total").First().Text()
		totalText = strings.TrimSpace(totalText)

		log.Printf("[%s] –ù–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç –≤ .search-results__total –¥–ª—è –ò–ù–ù %s: '%s'\n", logTraceID, COMPInn, totalText)

		newOrders := extractNumberFromText(totalText)
		newOrdersParsed, compHref, dateStart, dateUpdate, dateFinish := ParseHTML(doc)

		if newOrdersParsed > newOrders {
			newOrders = newOrdersParsed
		}

		if newOrders == 0 || compHref == "" {
			log.Printf("[%s] –ù–µ—Ç –Ω–æ–≤—ã—Ö –∑–∞–∫—É–ø–æ–∫ –¥–ª—è –ò–ù–ù %s\n", logTraceID, COMPInn)
			continue
		}

		if Contains(allOrdersHrefs, compHref) {
			log.Printf("[%s] –ó–∞–∫—É–ø–∫–∞ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: %s\n", logTraceID, compHref)
			continue
		}

		// –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ –∑–∞–∫—É–ø–∫–∞ –∫ "–≠–¢–ü –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω"
		if !IsValidOrder(compHref) {
			log.Printf("[%s] ‚ùå –ó–∞–∫—É–ø–∫–∞ %s –∏—Å–∫–ª—é—á–µ–Ω–∞ (–≠–¢–ü –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω)\n", logTraceID, compHref)
			continue
		}

		manager, exists := arUsers[COMPUserID]
		if !exists {
			manager = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä"
		}

		entry := fmt.Sprintf("%d) %s; –ò–ù–ù - %s; –†–∞–∑–º–µ—â–µ–Ω–æ/–û–±–Ω–æ–≤–ª–µ–Ω–æ/–û–∫–æ–Ω—á–∞–Ω–∏–µ - %s / %s / %s; –ö–æ–º–ø–∞–Ω–∏—è - https://torgi-crm.online/crm/company/details/%d/; –ì–æ—Å–∑–∞–∫—É–ø–∫–∞ - %s - %s\n",
			CompCount+1, COMPName, COMPInn, dateStart, dateUpdate, dateFinish, int(COMPID), compHref, manager)

		if CompCount%40 == 0 && CompCount != 0 {
			arrKey++
		}

		log.Printf("[%s] ‚úÖ –ù–∞–π–¥–µ–Ω–∞ –Ω–æ–≤–∞—è –∑–∞–∫—É–ø–∫–∞ –¥–ª—è –ò–ù–ù %s: %s\n", logTraceID, COMPInn, compHref)

		newCompaniesListArr[arrKey] += entry
		allOrdersHrefs = append(allOrdersHrefs, compHref)
		CompCount++
		processedCount++
	}

	log.Printf("[%s] –í—Å–µ–≥–æ –Ω–æ–≤—ã—Ö –∑–∞–∫—É–ø–æ–∫ –Ω–∞–π–¥–µ–Ω–æ: %d\n", logTraceID, CompCount)
	return allOrdersHrefs, newCompaniesListArr
}

func ParseHTML(doc *goquery.Document) (int, string, string, string, string) {
	var (
		newOrders  int
		compHref   string
		dateStart  string
		dateUpdate string
		dateFinish string
	)

	// –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–∞ #7
	element := doc.Find(".common-text__value").Eq(6) // –ò–Ω–¥–µ–∫—Å 6 –¥–ª—è —Å–µ–¥—å–º–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ (–Ω—É–º–µ—Ä–∞—Ü–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 0)
	text := strings.TrimSpace(element.Text())

	log.Printf("–ó–Ω–∞—á–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–∞ #7: %s", text)

	// –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞, –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
	if strings.Contains(text, "–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω") {
		log.Printf("–ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω, –Ω–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç '–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è –¢–æ—Ä–≥–æ–≤–∞—è –ü–ª–æ—â–∞–¥–∫–∞ –¢–æ—Ä–≥–∏-–û–Ω–ª–∞–π–Ω'")
		return 0, "", "", "", ""
	}

	// Extract total number of orders
	totalText := doc.Find(".search-results__total").First().Text()
	if num, err := strconv.Atoi(strings.TrimSpace(totalText)); err == nil {
		newOrders = num
	}

	// Extract procurement link
	doc.Find(".registry-entry__header-mid__number a").First().Each(func(i int, s *goquery.Selection) {
		href, exists := s.Attr("href")
		if exists {
			compHref = href
			if !strings.HasPrefix(compHref, "https://") {
				compHref = "https://zakupki.gov.ru" + compHref
			}
		}
	})

	// Extract date values
	doc.Find(".data-block__value").Each(func(i int, s *goquery.Selection) {
		switch i {
		case 0:
			dateStart = s.Text()
		case 1:
			dateUpdate = s.Text()
		case 2:
			dateFinish = s.Text()
		}
	})

	return newOrders, compHref, dateStart, dateUpdate, dateFinish
}

func Contains(slice []string, item string) bool {
	for _, v := range slice {
		if v == item {
			return true
		}
	}
	return false
}

// fetchHTML Deprecated?
func fetchHTML(inn, date string) *goquery.Document {
	time.Sleep(500 * time.Millisecond) // Delay to prevent server blocking

	url := fmt.Sprintf("https://zakupki.gov.ru/epz/order/extendedsearch/results.html?searchString=%s&morphology=on&search-filter=%D0%94%D0%B0%D1%82%D0%B5+%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%89%D0%B5%D0%BD%D0%B8%D1%8F&pageNumber=1&sortDirection=false&recordsPerPage=_10&showLotsInfoHidden=false&sortBy=UPDATE_DATE&fz223=on&af=on&currencyIdGeneral=-1&publishDateFrom=%s", inn, date)

	// –í—ã–ø–æ–ª–Ω—è–µ–º HTTP-–∑–∞–ø—Ä–æ—Å
	resp, err := http.Get(url)
	if err != nil {
		log.Printf("Failed to fetch URL: %s, error: %s\n", url, err)
		return nil
	}
	defer resp.Body.Close()

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞
	if resp.StatusCode != http.StatusOK {
		log.Printf("Unexpected HTTP status: %d for URL: %s\n", resp.StatusCode, url)
		return nil
	}

	// –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç Document –∏–∑ —Ç–µ–ª–∞ –æ—Ç–≤–µ—Ç–∞
	doc, err := goquery.NewDocumentFromReader(resp.Body)
	if err != nil {
		log.Printf("Failed to parse HTML for INN %s: %s\n", inn, err)
		return nil
	}

	return doc
}
